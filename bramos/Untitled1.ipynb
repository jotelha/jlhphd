{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def minimize_cmd(system_name,\n",
    "        lmp_suffix_template='-v baseName {baseName:s} -v dataFile {dataFile:s}'):\n",
    "        \"\"\"\n",
    "        Sample for lmp_suffix: for a call like\n",
    "            srun lmp -in lmp_minimization.input \\\n",
    "                -v has_indenter 1 -v robust_minimization 0 -v pbc2d 1 \\\n",
    "                -v baseName 377_SDS_on_AU_111_51x30x2_monolayer \\\n",
    "                -v dataFile 377_SDS_on_AU_111_51x30x2_monolayer.lammps\n",
    "        set lmp_suffix='-v has_indenter 1 -v robust_minimization 0 -v pbc2d 1 \\\n",
    "            -v baseName {baseName:s} -v dataFile {dataFile:s}'\n",
    "        \"\"\"\n",
    "        \n",
    "        consecutive_fw_list = []\n",
    "\n",
    "        get_input_files_ft = GetFilesTask( {\n",
    "                'identifiers':    [ 'lmp_header.input', \n",
    "                                   'lmp_minimization.input',\n",
    "                                   #'extract_thermo.sh',\n",
    "                                   system_name+'_psfgen.data' ] ,\n",
    "                'new_file_names': [ 'lmp_header.input',\n",
    "                                   'lmp_minimization.input',\n",
    "                                   #'extract_thermo.sh',\n",
    "                                   'datafile.lammps']} )\n",
    "        \n",
    "        \n",
    "        get_input_files_fw = Firework( get_input_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_out\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_minimization\":'lmp_minimization.input', \n",
    "                #                \"extract_thermo\":'extract_thermo.sh', \n",
    "                               \"datafile\": 'datafile.lammps'},\n",
    "                \"step\"   :     \"get_files\",\n",
    "                },\n",
    "            name=(system_name + \"get_files\") \n",
    "        )\n",
    "        consecutive_fw_list.append(get_input_files_fw)\n",
    "                \n",
    "        minimization_ft=CmdTask({'cmd': 'lmp',\n",
    "                                 'opt':\n",
    "                                 {'-in lmp_minimization.input',\n",
    "                                  '-v baseName '+ system_name,\n",
    "                                  '-v dataFile '+ 'datafile.lammps'},\n",
    "                                 'stdout_file':  'lmp_minimization.out',\n",
    "                                 'stderr_file':  'lmp_minimization.err',\n",
    "                                 'use_shell':    True,\n",
    "                                 'fizzle_bad_rc':True\n",
    "                                })\n",
    "\n",
    "        extract_thermo_ft =  CmdTask({'cmd': 'extract_thermo.sh',\n",
    "                                      'opt':\n",
    "                                      {system_name + '_minimization.log',\n",
    "                                       system_name + '_minimization_thermo.out'},\n",
    "                                      'stderr_file':'extract_thermo.err',\n",
    "                                      'stdout_file':'extract_thermo.out',\n",
    "                                      'fizzle_bad_rc':'false',\n",
    "                                      'use_shell':'true'\n",
    "                                     })      \n",
    "               \n",
    "        #extract_thermo_ft =  ScriptTask.from_str(\n",
    "        #    'bash extract_thermo.sh {:s} {:s}'.format(\n",
    "        #        system_name + '_minimization.log',\n",
    "        #        system_name + '_minimization_thermo.out'),\n",
    "        #       {\n",
    "        #            'use_shell':    True, 'fizzle_bad_rc': False\n",
    "        #        } )\n",
    "\n",
    "        fw = Firework(\n",
    "            [\n",
    "                minimization_ft#,\n",
    "                #extract_thermo_ft\n",
    "            ],\n",
    "            spec={\n",
    "                \"_category\":    \"nemo_queue_offline\",\n",
    "                \"_files_in\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_minimization\":'lmp_minimization.input', \n",
    "                                #\"extract_thermo\":'extract_thermo.sh', \n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"_files_out\":  {\"lmp_minimized\":system_name + '.lammps'},\n",
    "                \"system_name\": system_name,\n",
    "                \"step\"     : \"minimization\"\n",
    "            },\n",
    "            name=\"{:s}_minimzation\".format(system_name),\n",
    "            parents=[get_input_files_fw] )\n",
    "        \n",
    "        consecutive_fw_list.append(fw)\n",
    "        \n",
    "        add_output_files_ft= AddFilesTask({'compress':True ,\n",
    "                                           'identifier': [ system_name + '_minimized.lammps'], \n",
    "                                           'paths': [ system_name + '.lammps']})\n",
    "        \n",
    "        \n",
    "        add_output_files_fw = Firework(add_output_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_in\":  { \"lmp_minimized\":system_name + '.lammps' },\n",
    "                \"step\"   :     \"add_output_files\",\n",
    "                },\n",
    "            name=(system_name + \"add_output_files\"),\n",
    "            parents=[fw]\n",
    "       )\n",
    "        consecutive_fw_list.append(add_output_files_fw)\n",
    "        \n",
    "        parent_links = { consecutive_fw_list[i] : consecutive_fw_list[i+1] \\\n",
    "                        for i in range(len(consecutive_fw_list)-1) }\n",
    "\n",
    "        return Workflow( consecutive_fw_list, parent_links,\n",
    "            name=\"{:s}_min_wf\".format(system_name) )\n",
    "\n",
    "    \n",
    "def nvtEquilibrate_cmd(system_name,\n",
    "        lmp_suffix_template='-v baseName {baseName:s} -v dataFile {dataFile:s}'):\n",
    "        \"\"\"\n",
    "        Sample for lmp_suffix: for a call like\n",
    "            srun lmp -in lmp_equilibration_nvt.input \\\n",
    "                -v has_indenter 0 -v pbc2d 0 -v reinitialize_velocities 1\\\n",
    "                -v baseName 377_SDS_on_AU_111_51x30x2_monolayer \\\n",
    "                -v dataFile 377_SDS_on_AU_111_51x30x2_monolayer.lammps\n",
    "        set lmp_suffix='-v has_indenter 0 -v reinitialize_velocities 1 \\\n",
    "            -v baseName {baseName:s} -v dataFile {dataFile:s}'\n",
    "        \"\"\"\n",
    "\n",
    "        consecutive_fw_list = []\n",
    "        \n",
    "        get_input_files_ft = GetFilesTask( {\n",
    "                'identifiers':    ['lmp_header.input', \n",
    "                                   'lmp_equilibration_nvt.input', \n",
    "                                   #'extract_thermo.sh', \n",
    "                                   system_name + '_minimized.lammps'\n",
    "                                  ],\n",
    "                'new_file_names': ['lmp_header.input', \n",
    "                                   'lmp_equilibration_nvt.input',\n",
    "                                   #'extract_thermo.sh',\n",
    "                                   'datafile.lammps']} )\n",
    "        \n",
    "        get_input_files_fw = Firework( get_input_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_out\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_equilibration\":'lmp_equilibration.input', \n",
    "                                #\"extract_thermo\":'extract_thermo.sh', \n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"step\"   :     \"get_files\",\n",
    "                },\n",
    "            name=(system_name + \"get_files\") \n",
    "        )\n",
    "        consecutive_fw_list.append(get_input_files_fw)\n",
    "        \n",
    "        \n",
    "        lmp_ft=CmdTask({'cmd': 'lmp',\n",
    "                                 'opt':\n",
    "                                 {'-in lmp_equilibration_nvt.input',\n",
    "                                  '-v baseName '+ system_name,\n",
    "                                  '-v dataFile '+ 'datafile.lammps'},\n",
    "                                 'stdout_file':  'lmp_nvtEquilibration.out',\n",
    "                                 'stderr_file':  'lmp_nvtEquilibration.err',\n",
    "                                 'use_shell':    True,\n",
    "                                 'fizzle_bad_rc':True\n",
    "                                })\n",
    "\n",
    "        extract_thermo_ft =  CmdTask({'cmd': 'extract_thermo.sh',\n",
    "                                      'opt':\n",
    "                                      {system_name + '_nvtEquilibration.log',\n",
    "                                       system_name + '_nvtEquilibration_thermo.out'},\n",
    "                                      'stderr_file':'extract_thermo.err',\n",
    "                                      'stdout_file':'extract_thermo.out',\n",
    "                                      'fizzle_bad_rc':'false',\n",
    "                                      'use_shell':'true'\n",
    "                                     })      \n",
    "\n",
    "        #extract_thermo_ft =  ScriptTask.from_str(\n",
    "        #   'bash extract_thermo.sh {:s} {:s}'.format(\n",
    "        #        system_name + '_nvtEquilibration.log',\n",
    "        #        system_name + '_nvtEquilibration_thermo.out'),\n",
    "        #        {\n",
    "        #            'use_shell':    True, 'fizzle_bad_rc': False\n",
    "        #        } )\n",
    "\n",
    "        fw = Firework(\n",
    "            [\n",
    "                lmp_ft#,\n",
    "                #extract_thermo_ft\n",
    "            ],\n",
    "            spec={\n",
    "             \n",
    "                \"_category\":    \"nemo_queue_offline\",\n",
    "                \"system_name\": system_name,\n",
    "                \"_files_in\":  { \"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_equilibration\":'lmp_equilibration_nvt.input', \n",
    "                                #\"extract_thermo\":'extract_thermo.sh', \n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"_files_out\":  {\"lmp_nvt\": system_name + '.lammps'},\n",
    "                \"step\"     :   \"equilibration_nvt\",\n",
    "            },\n",
    "            name=\"{:s}_equilibration_nvt\".format(system_name),\n",
    "            parents=[get_input_files_fw] )\n",
    "        \n",
    "        \n",
    "        consecutive_fw_list.append(fw)\n",
    "    \n",
    "        add_output_files_ft= AddFilesTask({'compress':True ,\n",
    "                                           'identifier': [ system_name + '_nvtEquilibrated.lammps'],\n",
    "                                           'paths': [ system_name + '.lammps']})\n",
    "        \n",
    "        \n",
    "        add_output_files_fw = Firework(add_output_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_in\":  { \"lmp_nvt\": system_name + '.lammps'},\n",
    "                \"step\"   :     \"add_output_files\",\n",
    "                },\n",
    "            name=(system_name + \"add_output_files\"),\n",
    "            parents=[fw]\n",
    "       )\n",
    "        consecutive_fw_list.append(add_output_files_fw)\n",
    "        \n",
    "        parent_links = { consecutive_fw_list[i] : consecutive_fw_list[i+1] \\\n",
    "                        for i in range(len(consecutive_fw_list)-1) }\n",
    "\n",
    "        return Workflow( consecutive_fw_list, parent_links,\n",
    "            name=\"{:s}_nvt_wf\".format(system_name) )\n",
    "    \n",
    "\n",
    "\n",
    "def nptEquilibrate_cmd(system_name,\n",
    "        lmp_suffix_template='-v baseName {baseName:s} -v dataFile {dataFile:s}'):\n",
    "        \"\"\"\n",
    "        Sample for lmp_suffix: for a call like\n",
    "            srun lmp -in lmp_equilibration_npt.input \\\n",
    "                -v has_indenter 1 -v pbc2d 0 -v reinitialize_velocities 1\\\n",
    "                -v baseName 377_SDS_on_AU_111_51x30x2_monolayer \\\n",
    "                -v dataFile 377_SDS_on_AU_111_51x30x2_monolayer.lammps\n",
    "        set lmp_suffix='-v has_indenter 1 -v reinitialize_velocities 1 \\\n",
    "            -v baseName {baseName:s} -v dataFile {dataFile:s}'\n",
    "        \"\"\"\n",
    "        consecutive_fw_list = []\n",
    "\n",
    "        get_input_files_ft = GetFilesTask( {\n",
    "                'identifiers':    ['lmp_header.input', \n",
    "                                   'lmp_equilibration_npt.input', \n",
    "                                   #'extract_thermo.sh',\n",
    "                                   system_name + '_nvtEquilibrated.lammps'\n",
    "                                  ],\n",
    "                'new_file_names': [ 'lmp_header.input', \n",
    "                                   'lmp_equilibration_npt.input', \n",
    "                                   #'extract_thermo.sh',\n",
    "                                   'datafile.lammps']} )\n",
    "        \n",
    "        get_input_files_fw = Firework( get_input_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_out\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_equilibration\":'lmp_equilibration_npt.input', \n",
    "                                #\"extract_thermo\":'extract_thermo.sh',\n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"step\"   :     \"get_files\",\n",
    "                },\n",
    "            name=(system_name + \"get_files\")\n",
    "                                      \n",
    "        )\n",
    "        consecutive_fw_list.append(get_input_files_fw)\n",
    "        \n",
    "        \n",
    "        lmp_ft=CmdTask({'cmd': 'lmp',\n",
    "                        'opt':\n",
    "                        {'-in lmp_equilibration_npt.input',\n",
    "                         '-v baseName '+ system_name,\n",
    "                         '-v dataFile '+ 'datafile.lammps'},\n",
    "                        'stdout_file':  'lmp_nptEquilibration.out',\n",
    "                        'stderr_file':  'lmp_nptEquilibration.err',\n",
    "                        'use_shell':    True,\n",
    "                        'fizzle_bad_rc':True\n",
    "                       })\n",
    "\n",
    "        extract_thermo_ft =  CmdTask({'cmd': 'extract_thermo.sh',\n",
    "                                      'opt':\n",
    "                                      {system_name + '_nptEquilibration.log',\n",
    "                                       system_name + '_nptEquilibration_thermo.out'},\n",
    "                                      'stderr_file':'extract_thermo.err',\n",
    "                                      'stdout_file':'extract_thermo.out',\n",
    "                                      'fizzle_bad_rc':'false',\n",
    "                                      'use_shell':'true'\n",
    "                                     })      \n",
    "        fw = Firework(\n",
    "            [\n",
    "                lmp_ft#,\n",
    "                #extract_thermo_ft\n",
    "            ],\n",
    "            spec={\n",
    "                \"_category\": \"nemo_queue_offline\",\n",
    "                \"system_name\": system_name,\n",
    "                \"step\"     :   \"equilibration_npt\",\n",
    "                \"_files_in\":  { \"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_equilibration\":'lmp_equilibration_npt.input', \n",
    "                               #\"extract_thermo\":'extract_thermo.sh',\n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"_files_out\": {\"lmp_npt\":  system_name + '.lammps'}\n",
    "            },\n",
    "            name=\"{:s}_equilibration_npt\".format(system_name),\n",
    "            parents=[get_input_files_fw])\n",
    "        \n",
    "        consecutive_fw_list.append(fw)\n",
    "        \n",
    "        add_output_files_ft= AddFilesTask({'compress':True ,\n",
    "                                           'identifier': [ system_name + '_nptEquilibrated.lammps'], \n",
    "                                           'paths': [ system_name + '.lammps']})\n",
    "        \n",
    "        add_output_files_fw = Firework(add_output_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_in\":  { \"lmp_npt\": system_name + '.lammps'},\n",
    "                \"step\"   :     \"add_output_files\",\n",
    "                },\n",
    "            name=(system_name + \"add_output_files\"),\n",
    "            parents=[fw]\n",
    "       )\n",
    "        consecutive_fw_list.append(add_output_files_fw)\n",
    "        \n",
    "        parent_links = { consecutive_fw_list[i] : consecutive_fw_list[i+1] \\\n",
    "                        for i in range(len(consecutive_fw_list)-1) }\n",
    "\n",
    "        return Workflow( consecutive_fw_list, parent_links,\n",
    "            name=\"{:s}_npt_wf\".format(system_name) )\n",
    "\n",
    "def production_cmd(system_name,\n",
    "        total_steps      = 5000000, # time steps, 5 mio ~ 10 ns\n",
    "        lmp_suffix_template=' '.join((\n",
    "            '-v baseName {baseName:s} -v dataFile {dataFile:s}',\n",
    "            '-v has_indenter 0 -v pbc2d 0 -v mpiio 0 -v use_colvars 0')) ):\n",
    "        \"\"\"\n",
    "        Sample for lmp_suffix: for a call like\n",
    "            srun lmp -in lmp_production.input \\\n",
    "                -v has_indenter 0 -v pbc2d 0 -v mpiio 0 \\\n",
    "                -v thermo_frequency 1000 -v reinitialize_velocities 0 \\\n",
    "                -v use_colvars 0 -v productionSteps 1000 \\\n",
    "                -v baseName 377_SDS_on_AU_111_51x30x2_monolayer \\\n",
    "                -v dataFile 377_SDS_on_AU_111_51x30x2_monolayer.lammps\n",
    "        set lmp_suffix='-v has_indenter 0 -v reinitialize_velocities 0 \\\n",
    "            -v baseName {baseName:s} -v dataFile {dataFile:s} ...'\n",
    "        \"\"\"\n",
    "        consecutive_fw_list = []\n",
    "        \n",
    "        get_input_files_ft = GetFilesTask( {'identifiers':    ['lmp_header.input',\n",
    "                                                               'lmp_production.input',\n",
    "                                                               'lmp_production_mixed.input',\n",
    "                                                               #'extract_thermo.sh' , \n",
    "                                                               system_name + '_nptEquilibrated.lammps'],\n",
    "                                            'new_file_names': ['lmp_header.input',\n",
    "                                                               'lmp_production.input',\n",
    "                                                               'lmp_production_mixed.input',\n",
    "                                                               #'extract_thermo.sh',\n",
    "                                                               'datafile.lammps']} )\n",
    "        \n",
    "        get_input_files_fw = Firework( get_input_files_ft,\n",
    "            spec = {\n",
    "                \"_category\":  \"nemo_noqueue\",\n",
    "                \"system_name\" : system_name,\n",
    "                \"_files_out\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_production\":'lmp_production.input', \n",
    "                                'lmp_production_mixed':'lmp_production_mixed.input',\n",
    "                                #\"extract_thermo\":'extract_thermo.sh',\n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"step\"   :     \"get_files\",\n",
    "                },\n",
    "            name=(system_name + \"get_files\")\n",
    "                                      \n",
    "        )\n",
    "        consecutive_fw_list.append(get_input_files_fw)\n",
    "        \n",
    "        lmp_cmd = ' '.join((\n",
    "            'module load lammps/08May19-git-master-gnu-7.3-openmpi-3.1-colvars-08May19;',\n",
    "            'mpirun -n 16 lmp -in '+ 'lmp_production.input' , lmp_suffix_template.format(\n",
    "                baseName= system_name, dataFile='datafile.lammps' ) ) )\n",
    "\n",
    "        lmp_ft =  ScriptTask.from_str(\n",
    "            lmp_cmd,\n",
    "            {\n",
    "                'stdout_file':  'lmp_production.out',\n",
    "                'stderr_file':  'lmp_production.err',\n",
    "                'use_shell':    True,\n",
    "                'fizzle_bad_rc':True\n",
    "            })\n",
    "        \n",
    "                    \n",
    "        lmp_ft=CmdTask({'cmd': 'lmp',\n",
    "                                'opt':\n",
    "                                 {'-in lmp_production.input',\n",
    "                                  '-v baseName '+ system_name,\n",
    "                                  '-v dataFile '+ 'datafile.lammps'},\n",
    "                                 'stdout_file':  'lmp_production.out',\n",
    "                                 'stderr_file':  'lmp_production.err',\n",
    "                                 'use_shell':    True,\n",
    "                                 'fizzle_bad_rc':True\n",
    "                                })\n",
    "\n",
    "        extract_thermo_ft =  CmdTask({'cmd': 'extract_thermo.sh',\n",
    "                                      'opt':\n",
    "                                      {system_name + '_production.log',\n",
    "                                       system_name + '_production_thermo.out'},\n",
    "                                      'stderr_file':'extract_thermo.err',\n",
    "                                      'stdout_file':'extract_thermo.out',\n",
    "                                      'fizzle_bad_rc':'false',\n",
    "                                      'use_shell':'true'\n",
    "                                     })     \n",
    "\n",
    "        fw = Firework(\n",
    "            [\n",
    "                lmp_ft#,\n",
    "                #extract_thermo_ft,\n",
    "                #*tail_ft_list\n",
    "            ],\n",
    "            spec={\n",
    "                \"_category\":     \"nemo_queue_offline\",\n",
    "                \"system_name\":    system_name,\n",
    "                \"_files_in\":  {\"lmp_header\":'lmp_header.input', \n",
    "                                \"lmp_production\":'lmp_production.input', \n",
    "                                'lmp_production_mixed':'lmp_production_mixed.input',\n",
    "                                #\"extract_thermo\":'extract_thermo.sh',\n",
    "                                \"datafile\": 'datafile.lammps'},\n",
    "                \"step\"     :      \"production\",\n",
    "                \"total_steps\":    total_steps,\n",
    "            },\n",
    "            name=\"{:s}_produtcion_{:d}\".format(system_name, total_steps) ,\n",
    "            parents=[get_input_files_fw])\n",
    "        \n",
    "        consecutive_fw_list.append(add_output_files_fw)\n",
    "        \n",
    "        parent_links = { consecutive_fw_list[i] : consecutive_fw_list[i+1] \\\n",
    "                        for i in range(len(consecutive_fw_list)-1) }\n",
    "\n",
    "        return Workflow( consecutive_fw_list, parent_links,\n",
    "            name=\"{:s}_production_wf\".format(system_name) )\n",
    "\n",
    "\n",
    "def run_minimize_cmd(inputs):\n",
    "    minimize_wfs= ['' for x in range((len(inputs)))] \n",
    "    lmp_suffix_template= '-v baseName {baseName:s} -v dataFile {dataFile:s} '\n",
    "    for i in range((len(inputs))):\n",
    "        inputs_single=inputs[i]\n",
    "        minimize_wfs[i]=minimize_cmd(inputs_single[\"system_name\"],lmp_suffix_template)\n",
    "    return FWAction(detours=minimize_wfs )\n",
    "\n",
    "def run_nvtEquilibrate_cmd(inputs):\n",
    "    nvtEquilibrate_wfs= ['' for x in range((len(inputs)))] \n",
    "    lmp_suffix_template='-v baseName {baseName:s} -v dataFile {dataFile:s} '\n",
    "    for i in range((len(inputs))):\n",
    "        inputs_single=inputs[i]\n",
    "        minimize_wfs[i]=nvtEquilibrate_cmd(inputs_single[\"system_name\"],lmp_suffix_template)\n",
    "    return FWAction(detours=nvtEquilibrate_wfs )\n",
    "\n",
    "def run_nptEquilibrate_cmd(inputs):\n",
    "    nptEquilibrate_wfs= ['' for x in range((len(inputs)))] \n",
    "    lmp_suffix_template='-v baseName {baseName:s} -v dataFile {dataFile:s} '\n",
    "    for i in range((len(inputs))):\n",
    "        inputs_single=inputs[i]\n",
    "        nptEquilibrate_wfs[i]=nptEquilibrate_cmd(inputs_single[\"system_name\"],lmp_suffix_template)\n",
    "    return FWAction(detours=nptEquilibrate_wfs )\n",
    "\n",
    "def production_cmd(inputs):\n",
    "    production_wfs= ['' for x in range((len(inputs)))] \n",
    "    lmp_suffix_template= '-v baseName {baseName:s} -v dataFile {dataFile:s} '\n",
    "    for i in range((len(inputs))):\n",
    "        inputs_single=inputs[i]\n",
    "        production_wfs[i]=production_cmd(inputs_single[\"system_name\"],lmp_suffix_template)\n",
    "    return FWAction(detours=production_wfs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireworks.user_objects.dupefinders.dupefinder_exact import DupeFinderExact\n",
    "from fireworks.user_objects.firetasks.fileio_tasks import FileTransferTask, FileWriteTask\n",
    "from fireworks.user_objects.firetasks.script_task import ScriptTask, PyTask\n",
    "from fireworks.user_objects.firetasks.templatewriter_task import TemplateWriterTask\n",
    "from fireworks.user_objects.firetasks.filepad_tasks import AddFilesTask, GetFilesTask, DeleteFilesTask\n",
    "from fireworks import Firework, LaunchPad, Workflow, FWorker, FireTaskBase, FWAction\n",
    "import os\n",
    "import scipy.constants as C\n",
    "import numpy as np\n",
    "\n",
    "def run_replicate(dimensions,surfactants,sf_nmolecules,counterion,preassembly,sb_unit,ncylinders):\n",
    "    inputs=get_inputs(dimensions,surfactants,sf_nmolecules,counterion,preassembly,sb_unit,ncylinders)\n",
    "    replicate_fw=sb_replicate(inputs)\n",
    "    return FWAction(stored_data={'inputs':inputs}, mod_spec=[{'_set': {'inputs': inputs}}], detours=replicate_fw)\n",
    "\n",
    "\n",
    "def sb_replicate(inputs):\n",
    "    dimensions=(inputs[0])[\"sb_multiples\"]\n",
    "    xyz=(dimensions[0])+' '+(dimensions[1])+' '+(dimensions[2])+' '\n",
    "    sb_name=(inputs[0])[\"sb_name\"]\n",
    "    in_dimensions= xyz + '111' \n",
    "    cmd_run = ' '.join(('module load Fireworks; module load GROMACS/2018.1-gnu-7.3-openmpi-2.1.1; module load MDTools;', 'replicate.sh {:s}'.format(in_dimensions) ))\n",
    "    replicate_ft =  ScriptTask.from_str( cmd_run ,{\n",
    "                'use_shell':    True } )\n",
    "    \n",
    "    replicate_get_ft = GetFilesTask( {\n",
    "                'identifiers': [ 'au_cell_P1_111.gro']} )\n",
    "    replicate_set_ft = AddFilesTask({'compress':True ,'identifiers': ['{:s}.pdb'.format(sb_name)], 'paths': \"{:s}.pdb\".format(sb_name)})\n",
    "    replicate_fw = Firework(\n",
    "        [ replicate_get_ft, replicate_ft,replicate_set_ft\n",
    "            ],\n",
    "            spec={\n",
    "                \"_category\":   \"bwcloud_noqueue\",\n",
    "                \"step\"     :   \"replicate\",\n",
    "            },\n",
    "            name= 'replicate' )\n",
    "    return replicate_fw\n",
    "\n",
    "def get_inputs(dimensions,surfactants,sf_nmolecules,counterion,preassembly,sb_unit,ncylinders):\n",
    "    sb_name= 'AU_111_'+dimensions[0]+'x'+dimensions[1]+'x'+dimensions[2]\n",
    "    system_name=[sf_nmolecules+'_'+surfactants[i]+'_on_'+sb_name+'_'+preassembly[j]  for i in range(len(surfactants))  for j in range(len(preassembly))]\n",
    "    sb_measures=np.asarray(list(map(int,dimensions)))*np.asarray(list(map(float,sb_unit)))\n",
    "    sb_measures= list(map(str,sb_measures))\n",
    "    #box=[sb_measures[0],sb_measures[1],1.8e-08]\n",
    "    inputs = [dict() for i in range(len(preassembly)*len(surfactants))]\n",
    "    for i in range(len(surfactants)):\n",
    "        for j in range(len(preassembly)):\n",
    "            my_dict={\n",
    "                       \"sb_measures\": sb_measures,\n",
    "                       \"sb_multiples\":dimensions,\n",
    "                       \"sb_unit\":sb_unit,\n",
    "                       \"surfactant\":surfactants[i] ,\n",
    "                       \"preassembly\":preassembly[j],\n",
    "                       \"ncylinders\": ncylinders,\n",
    "                       \"sb_name\":sb_name,\n",
    "                       \"sf_nmolecules\":sf_nmolecules,\n",
    "                       \"counterion\": counterion,\n",
    "                       \"system_name\":system_name[i*len(preassembly)+j]}\n",
    "            inputs[i*len(preassembly)+j]=my_dict\n",
    "    return inputs\n",
    "\n",
    "def run_packmol(inputs,nloop,maxit):\n",
    "    packmol_wfs= ['' for x in range((len(inputs)))] \n",
    "    for i in range((len(inputs))):\n",
    "        inputs_single=inputs[i]\n",
    "        if \"cylinders\" in inputs_single[\"preassembly\"]:\n",
    "            packmol=prepare_packmol(inputs_single,pack_cylinders,nloop,maxit,ncylinders)\n",
    "        elif \"bilayer\" in inputs_single[\"preassembly\"]:\n",
    "            packmol=prepare_packmol(inputs_single,pack_bilayer,nloop,maxit)\n",
    "        elif \"monolayer\" in inputs_single[\"preassembly\"]:\n",
    "            packmol=prepare_packmol(inputs_single,pack_monolayer,nloop,maxit)\n",
    "        packmol_wfs[i]=packmol\n",
    "    return FWAction(detours=packmol_wfs)   \n",
    "            \n",
    "\n",
    "def prepare_packmol(inputs, pack_aggregates, nloop = None, maxit = None ):\n",
    "        \"\"\"Creates preassembled aggregates on surface\"\"\"\n",
    "        #for system_name, row in sim_df.loc[system_names].iterrows():\n",
    "        tolerance = 2 # Angstrom\n",
    "        #No\n",
    "        #\n",
    "        \n",
    "        surfactant  = inputs[\"surfactant\"]\n",
    "        counterion  = inputs[\"counterion\"]\n",
    "        sfN         = int(inputs[\"sf_nmolecules\"])\n",
    "        sb_name     = inputs[\"sb_name\"]\n",
    "        system_name=  inputs[\"system_name\"]\n",
    "        # measures of substrate:\n",
    "        #No\n",
    "        sb_measures=  list(map(float,inputs[\"sb_measures\"]))\n",
    "        sb_measures = np.asarray(sb_measures) / C.angstrom\n",
    "        #\n",
    "        ncylinders=  int(inputs[\"ncylinders\"])\n",
    "        # standard settings can be overridden\n",
    "        #No\n",
    "        packmol_script_writer_task_context = {\n",
    "            'system_name':   system_name,\n",
    "            'sb_name':       sb_name,\n",
    "            'tolerance':     tolerance,\n",
    "            'write_restart': True\n",
    "        }\n",
    "        #\n",
    "        if nloop is not None:\n",
    "            packmol_script_writer_task_context['nloop'] = nloop\n",
    "\n",
    "        if maxit is not None:\n",
    "            packmol_script_writer_task_context['maxit'] = maxit\n",
    "        \n",
    "        if \"cylinders\" in inputs[\"preassembly\"]:\n",
    "            if \"hemicylinders\" in inputs[\"preassembly\"]:\n",
    "                    packmol_script_writer_task_context.update(\n",
    "                        pack_aggregates(\n",
    "                            surfactant  = surfactant,\n",
    "                            counterion  = counterion,\n",
    "                            sfN = sfN,\n",
    "                            sb_measures = sb_measures,\n",
    "                            ncylinders=ncylinders,\n",
    "                            hemicylinders = True ))\n",
    "            else:\n",
    "                packmol_script_writer_task_context.update(\n",
    "                    pack_aggregates(\n",
    "                            surfactant  = surfactant,\n",
    "                            counterion  = counterion,\n",
    "                            sfN = sfN,\n",
    "                            sb_measures = sb_measures,\n",
    "                            ncylinders = ncylinders,\n",
    "                            hemicylinders = False\n",
    "                            ))\n",
    "        else:\n",
    "            packmol_script_writer_task_context.update(\n",
    "                pack_aggregates(\n",
    "                    surfactant  = surfactant,\n",
    "                    counterion  = counterion,\n",
    "                    sfN = sfN,\n",
    "                    sb_measures = sb_measures))\n",
    "     \n",
    "        packmol_get_template_ft = GetFilesTask( {\n",
    "                'identifiers': [ 'packmol.inp' ]} )\n",
    "        # packmol fill script template\n",
    "        packmol_fill_script_template_ft = TemplateWriterTask( {\n",
    "            'context' :      packmol_script_writer_task_context,\n",
    "            #'template_file': '/mnt/dat/work/testuser/adsorption/N_surfactant_on_substrate_template/packmol.inp',\n",
    "             'template_file': 'packmol.inp',\n",
    "            'output_file':   system_name + '_packmol' + '.inp' } )\n",
    "\n",
    "        packmol_fill_script_template_fw = Firework(\n",
    "            [ packmol_get_template_ft,\n",
    "            packmol_fill_script_template_ft],\n",
    "            spec={\n",
    "                \"_category\": \"bwcloud_noqueue\",\n",
    "                '_files_out': {\n",
    "                    'packmol_inp': system_name + '_packmol.inp'\n",
    "                    },\n",
    "                \"system_name\": system_name,\n",
    "                \"step\"   :     \"packmol_fill_script_template\",\n",
    "            },\n",
    "            name=\"{:s}_packmol_fill_script_template\".format(system_name) )\n",
    "\n",
    "    # packmol get building blocks #database\n",
    "        single_surfactant_pdb = '1_{:s}.pdb'.format(surfactant)\n",
    "        single_counterion_pdb = '1_{:s}.pdb'.format(counterion)\n",
    "        \n",
    "        packmol_get_components_ft = GetFilesTask( {\n",
    "                'identifiers': [ single_surfactant_pdb ,single_counterion_pdb ],\n",
    "                'new_file_names': [ single_surfactant_pdb ,single_counterion_pdb] } )\n",
    "        #database'\n",
    "        packmol_get_substrate_ft = GetFilesTask( {\n",
    "                'identifiers': [ '{:s}.pdb'.format(sb_name) ],\n",
    "                'new_file_names': [ '{:s}.pdb'.format(sb_name) ] } )\n",
    "    # packmol run\n",
    "        infile= system_name + '_packmol.inp' \n",
    "        cmd_run = ' '.join(('module load MDTools;', 'packmol < {:s}'.format(infile) ))\n",
    "        packmol_ft =  ScriptTask.from_str( cmd_run ,{\n",
    "                'stdout_file':  system_name + '_packmol' + '.out',\n",
    "                'stderr_file':  system_name + '_packmol' + '.err',\n",
    "                'use_shell':    True,\n",
    "                'shell_exe': \"/bin/bash\",\n",
    "                'fizzle_bad_rc':True } )\n",
    "        packmol_add_files_ft= AddFilesTask({'compress':True ,\n",
    "                                            'identifiers': [system_name + '_packmol.inp', system_name + '_packmol.pdb'],\n",
    "                                            'paths':[ system_name + '_packmol.inp',system_name + '_packmol.pdb']})\n",
    "        \n",
    "        packmol_fw = Firework(\n",
    "            [\n",
    "                packmol_get_components_ft,\n",
    "                packmol_get_substrate_ft,\n",
    "                packmol_ft,\n",
    "                packmol_add_files_ft\n",
    "            ],\n",
    "            spec={\n",
    "                \"_category\":   \"bwcloud_noqueue\",\n",
    "                \"_files_in\" : {\n",
    "                    \"packmol_inp\":  (system_name + '_packmol.inp') },\n",
    "                \"_files_out\": {\n",
    "                    \"packmol_pdb\" : (system_name + '_packmol.pdb'),\n",
    "                    \"packmol_pdb_FORCED\" : (system_name + '_packmol.pdb_FORCED')\n",
    "                },\n",
    "                \"system_name\": system_name,\n",
    "                \"step\"     :   \"packmol\",\n",
    "            },\n",
    "            name= system_name + '_packmol',\n",
    "            parents=[packmol_fill_script_template_fw] )\n",
    "        \n",
    "        packmol_wf = Workflow(\n",
    "            [packmol_fill_script_template_fw,\n",
    "             packmol_fw\n",
    "            ],\n",
    "            {packmol_fill_script_template_fw: packmol_fw},\n",
    "            name = system_name + '_packmol' )\n",
    "\n",
    "        return packmol_wf\n",
    "\n",
    "\n",
    "def pack_cylinders(sb_measures, surfactant, counterion, sfN, hemicylinders,ncylinders):\n",
    "    if surfactant=='SDS':\n",
    "        l_surfactant = 14.0138 # Angstrom\n",
    "        head_atom_number = 1\n",
    "        tail_atom_number= 39\n",
    "    elif surfactant=='CTAB':    \n",
    "        l_surfactant = 19.934 # Angstrom\n",
    "        head_atom_number= 17\n",
    "        tail_atom_number= 1\n",
    "        # Tolerance in packmol\n",
    "    tolerance = 2 # Angstrom\n",
    "        #NA or BR\n",
    "    #counterion='NA'\n",
    "    \"\"\"Creates preassembled (hemi-) cylinders on substrate with couinterions at polar heads\"\"\"\n",
    "\n",
    "    hemistr = 'hemi-' if hemicylinders else ''\n",
    "    sbX, sbY, sbZ = sb_measures\n",
    "\n",
    "    # place box at coordinate zero in z-direction\n",
    "    sb_pos = - sb_measures / 2 * np.array( [1,1,0] )\n",
    "\n",
    "    sf_molecules_per_cylinder = sfN // ncylinders\n",
    "    excess_sf_molecules = sfN % ncylinders\n",
    "\n",
    "    cylinder_spacing = sbY / ncylinders\n",
    "\n",
    "    # cylinders parallelt to x-axis\n",
    "    cylinders = [{} for _ in range(ncylinders)]\n",
    "    ioncylinders = [{} for _ in range(ncylinders)]\n",
    "\n",
    "    # surfactant cylinders\n",
    "    #   inner constraint radius: 1*tolerance\n",
    "    #   outer constraint radius: 1*tolerance + l_surfactant\n",
    "     # ions between cylindric planes at\n",
    "    #  inner radius:            1*tolerance + l_surfactant\n",
    "        #   outer radius:            2*tolerance + l_surfactant\n",
    "    for n, cylinder in enumerate(cylinders):\n",
    "        cylinder[\"surfactant\"] = surfactant\n",
    "\n",
    "        if hemicylinders:\n",
    "            cylinder[\"upper_hemi\"] = True\n",
    "\n",
    "        cylinder[\"inner_atom_number\"] = tail_atom_number\n",
    "        cylinder[\"outer_atom_number\"] = head_atom_number\n",
    "\n",
    "        cylinder[\"N\"] = sf_molecules_per_cylinder\n",
    "        if n < excess_sf_molecules:\n",
    "            cylinder[\"N\"] += 1\n",
    "\n",
    "        # if packing hemicylinders, center just at substrate\n",
    "        cylinder[\"base_center\"] = [\n",
    "        sb_pos[0],\n",
    "        sb_pos[1] + (0.5 + float(n))*cylinder_spacing,\n",
    "        sb_measures[2] ]\n",
    "        \n",
    "        # if packing full cylinders, shift center by one radius in z dir\n",
    "        if not hemicylinders:\n",
    "            cylinder[\"base_center\"][2] += l_surfactant + 2*tolerance\n",
    "\n",
    "        cylinder[\"length\"] = sb_measures[0] - tolerance # to be on top of gold surfface\n",
    "        cylinder[\"radius\"] = 0.5*cylinder_spacing\n",
    "\n",
    "        cylinder[\"inner_constraint_radius\"] = tolerance\n",
    "\n",
    "        maximum_constraint_radius = (0.5*cylinder_spacing - tolerance)\n",
    "        cylinder[\"outer_constraint_radius\"] = tolerance + l_surfactant \\\n",
    "        if tolerance + l_surfactant < maximum_constraint_radius \\\n",
    "        else maximum_constraint_radius\n",
    "\n",
    "\n",
    "        # ions at outer surface\n",
    "        ioncylinders[n][\"ion\"] = counterion\n",
    "\n",
    "        if hemicylinders:\n",
    "            ioncylinders[n][\"upper_hemi\"] = True\n",
    "\n",
    "        ioncylinders[n][\"N\"] = cylinder[\"N\"]\n",
    "        ioncylinders[n][\"base_center\"] = cylinder[\"base_center\"]\n",
    "        ioncylinders[n][\"length\"] = cylinder[\"length\"]\n",
    "        ioncylinders[n][\"inner_radius\"] = cylinder[\"outer_constraint_radius\"]\n",
    "        ioncylinders[n][\"outer_radius\"] = cylinder[\"outer_constraint_radius\"] + tolerance\n",
    "\n",
    "\n",
    "    # experience shows: movebadrandom advantegous for (hemi-) cylinders\n",
    "    context = {\n",
    "        'sb_pos':        sb_pos,\n",
    "        'cylinders':     cylinders,\n",
    "        'ioncylinders':  ioncylinders,\n",
    "        'movebadrandom': True,\n",
    "        }\n",
    "    return context\n",
    "\n",
    "def pack_monolayer(sfN, sb_measures, surfactant, counterion ):\n",
    "        \"\"\"Creates preassembled monolayer\"\"\"\n",
    "\n",
    "        if surfactant=='SDS':\n",
    "            l_surfactant = 14.0138 # Angstrom\n",
    "            head_atom_number = 1\n",
    "            tail_atom_number= 39\n",
    "        elif surfactant=='CTAB':    \n",
    "            l_surfactant = 19.934 # Angstro\n",
    "            head_atom_number= 17\n",
    "            tail_atom_number= 1\n",
    "        \n",
    "        tolerance = 2 # Angstrom\n",
    "        sbX, sbY, sbZ = sb_measures\n",
    "        \n",
    "        # place box at coordinate zero in z-direction\n",
    "        sb_pos = - sb_measures / 2 * np.array( [1,1,0] )\n",
    "\n",
    "        # 1st monolayer above substrate, polar head towards surface\n",
    "        # NOT applying http://www.ime.unicamp.br/~martinez/packmol/userguide.shtml\n",
    "        # recommendation on periodic bc\n",
    "\n",
    "        na_layer_1_bb  = np.array([ [ - sbX / 2.,\n",
    "                                        sbX / 2. ],\n",
    "                                    [ - sbY / 2.,\n",
    "                                        sbY / 2. ],\n",
    "                                    [ sbZ,\n",
    "                                      sbZ + tolerance ] ])\n",
    "\n",
    "        monolayer_bb_1 = np.array([ [ - sbX / 2.,\n",
    "                                        sbX / 2. ],\n",
    "                                    [ - sbY / 2.,\n",
    "                                        sbY / 2. ],\n",
    "                                    [ sbZ,\n",
    "                                      sbZ + 2*tolerance + l_surfactant ] ] )\n",
    "\n",
    "        lower_constraint_plane_1 = sbZ + 1*tolerance\n",
    "        upper_constraint_plane_1 = sbZ + 1*tolerance + l_surfactant\n",
    "\n",
    "        monolayers = [\n",
    "            {\n",
    "                'surfactant':             surfactant,\n",
    "                'N':                      sfN,\n",
    "                'lower_atom_number':      tail_atom_number,\n",
    "                'upper_atom_number':      head_atom_number,\n",
    "                'bb_lower':               monolayer_bb_1[:,0],\n",
    "                'bb_upper':               monolayer_bb_1[:,1],\n",
    "                'lower_constraint_plane': lower_constraint_plane_1,\n",
    "                'upper_constraint_plane': upper_constraint_plane_1\n",
    "            } ]\n",
    "        ionlayers = [\n",
    "            {\n",
    "                'ion':                    counterion,\n",
    "                'N':                      sfN,\n",
    "                'bb_lower':               na_layer_1_bb[:,0],\n",
    "                'bb_upper':               na_layer_1_bb[:,1]\n",
    "            } ]\n",
    "\n",
    "        context = {\n",
    "            'sb_pos':     sb_pos,\n",
    "            'monolayers': monolayers,\n",
    "            'ionlayers':  ionlayers\n",
    "        }\n",
    "        return context\n",
    "\n",
    "def pack_bilayer(sfN, sb_measures, surfactant, counterion):\n",
    "        \"\"\"Creates a single bilayer on substrate with couinterions at polar heads\"\"\"\n",
    "        \n",
    "        if surfactant=='SDS':\n",
    "            l_surfactant = 14.0138 # Angstrom\n",
    "            head_atom_number = 1\n",
    "            tail_atom_number= 39\n",
    "        elif surfactant=='CTAB':    \n",
    "            l_surfactant = 19.934 # Angstro\n",
    "            head_atom_number= 17\n",
    "            tail_atom_number= 1\n",
    "        \n",
    "        tolerance = 2 # Angstrom\n",
    "        \n",
    "        \n",
    "        sbX, sbY, sbZ = sb_measures\n",
    "\n",
    "        # place box at coordinate zero in z-direction\n",
    "        sb_pos = - sb_measures / 2 * np.array( [1,1,0] )\n",
    "\n",
    "        N_inner_monolayer = (sfN // 2) + (sfN % 2)\n",
    "        N_outer_monolayer = sfN//2\n",
    "\n",
    "        na_layer_1_bb  = np.array([ [ - sbX / 2. ,\n",
    "                                        sbX / 2. ],\n",
    "                                    [ - sbY / 2. ,\n",
    "                                        sbY / 2. ],\n",
    "                                    [ sbZ,\n",
    "                                      sbZ + tolerance ] ])\n",
    "\n",
    "        monolayer_bb_1 = np.array([ [ - sbX / 2. ,\n",
    "                                        sbX / 2. ],\n",
    "                                    [ - sbY / 2. ,\n",
    "                                        sbY / 2.  ],\n",
    "                                    [ sbZ,\n",
    "                                      sbZ + 2*tolerance + l_surfactant ] ])\n",
    "\n",
    "        lower_constraint_plane_1 = sbZ + 1*tolerance\n",
    "        upper_constraint_plane_1 = sbZ + 1*tolerance + l_surfactant\n",
    "        z_shift_monolayer_2 = 1*tolerance + l_surfactant # overlap\n",
    "        z_shift_na_layer_2 =  2*z_shift_monolayer_2 - 1*tolerance\n",
    "\n",
    "        monolayer_bb_2 = monolayer_bb_1 + np.array([[0,0],[0,0],\n",
    "                                                    [z_shift_monolayer_2,\n",
    "                                                     z_shift_monolayer_2]])\n",
    "        lower_constraint_plane_2 = lower_constraint_plane_1 + z_shift_monolayer_2\n",
    "        upper_constraint_plane_2 = upper_constraint_plane_1 + z_shift_monolayer_2\n",
    "\n",
    "        na_layer_2_bb = na_layer_1_bb + np.array([[0,0],[0,0],\n",
    "                                                  [z_shift_na_layer_2,\n",
    "                                                   z_shift_na_layer_2]])\n",
    "\n",
    "        monolayers = [\n",
    "            {\n",
    "                'surfactant':             surfactant,\n",
    "                'N':                      N_inner_monolayer,\n",
    "                'lower_atom_number':      head_atom_number,\n",
    "                'upper_atom_number':      tail_atom_number,\n",
    "                'bb_lower':               monolayer_bb_1[:,0],\n",
    "                'bb_upper':               monolayer_bb_1[:,1],\n",
    "                'lower_constraint_plane': lower_constraint_plane_1,\n",
    "                'upper_constraint_plane': upper_constraint_plane_1\n",
    "            },\n",
    "            {\n",
    "                'surfactant':             surfactant,\n",
    "                'N':                      N_outer_monolayer,\n",
    "                'lower_atom_number':      tail_atom_number,\n",
    "                'upper_atom_number':      head_atom_number,\n",
    "                'bb_lower':               monolayer_bb_2[:,0],\n",
    "                'bb_upper':               monolayer_bb_2[:,1],\n",
    "                'lower_constraint_plane': lower_constraint_plane_2,\n",
    "                'upper_constraint_plane': upper_constraint_plane_2\n",
    "            } ]\n",
    "        ionlayers = [\n",
    "            {\n",
    "                'ion':                    counterion,\n",
    "                'N':                      N_inner_monolayer,\n",
    "                'bb_lower':               na_layer_1_bb[:,0],\n",
    "                'bb_upper':               na_layer_1_bb[:,1]\n",
    "            },\n",
    "            {\n",
    "                'ion':                    counterion,\n",
    "                'N':                      N_outer_monolayer,\n",
    "                'bb_lower':               na_layer_2_bb[:,0],\n",
    "                'bb_upper':               na_layer_2_bb[:,1]\n",
    "            } ]\n",
    "\n",
    "        context = {\n",
    "            'sb_pos':     sb_pos,\n",
    "            'monolayers': monolayers,\n",
    "            'ionlayers':  ionlayers\n",
    "        }\n",
    "        return context\n",
    "\n",
    "def get_dimensions():\n",
    "    ini=0\n",
    "    fin=0\n",
    "    path=os.getcwd()\n",
    "    #path='/mnt/dat/work/testuser/adsorption/N_surfactant_on_substrate_template'\n",
    "    files = []\n",
    "    for i in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path,i)) and 'AU_111' in i:\n",
    "            files.append(i)\n",
    "    s=list(files[0])\n",
    "    count=0\n",
    "    for i in range(len(s)):\n",
    "        if s[i]=='1':\n",
    "            count+=1\n",
    "        if count==3:\n",
    "            ini=i\n",
    "            count=0\n",
    "            break\n",
    "    for i in range(ini,len(s)):\n",
    "        if s[i]=='_':\n",
    "            count+=1\n",
    "        if count==2:\n",
    "            fin=i\n",
    "            break\n",
    "    result=(''.join(s[ini+2:fin]))\n",
    "    return result\n",
    "\n",
    "def get_surfactants(dimensions,surfactants):\n",
    "    outputs=[surfactants[i]+'_on_AU_111_'+ dimensions  for i in range(len(surfactants))]\n",
    "    return outputs\n",
    "\n",
    "def get_preassembly(dim_surf,preassembly):\n",
    "    for i in range(len(dim_surf)):\n",
    "        outputs=[dim_surf[i]+'_'+ preassembly[j] for j in range(len(preassembly))]\n",
    "    return outputs\n",
    "\n",
    "def get_inputs_single(dim_surf_asb, sf_nmolecules, counterion, sb_unit,ncylinders):\n",
    "    dim_surf_asb=dim_surf_asb[0]\n",
    "    split_name=dim_surf_asb.split('_')\n",
    "    surfactants=[split_name[0]]\n",
    "    dimensions=split_name[4].split('x')\n",
    "    preassembly=['_'.join((split_name[5:]))]\n",
    "    sb_name= 'AU_111_'+dimensions[0]+'x'+dimensions[1]+'x'+dimensions[2]\n",
    "    system_name=[sf_nmolecules+'_'+surfactants[i]+'_on_'+sb_name+'_'+preassembly[j]  for i in range(len(surfactants))  for j in range(len(preassembly))]\n",
    "    sb_measures=np.asarray(list(map(int,dimensions)))*np.asarray(list(map(float,sb_unit)))\n",
    "    sb_measures= list(map(str,sb_measures))\n",
    "    inputs = [dict() for i in range(len(preassembly)*len(surfactants))]\n",
    "    for i in range(len(surfactants)):\n",
    "        for j in range(len(preassembly)):\n",
    "            my_dict={\n",
    "                       \"sb_measures\": sb_measures,\n",
    "                       \"sb_multiples\":dimensions,\n",
    "                       \"sb_unit\":sb_unit,\n",
    "                       \"surfactant\":surfactants[i] ,\n",
    "                       \"preassembly\":preassembly[j],\n",
    "                       \"sb_name\":sb_name,\n",
    "                       \"sf_nmolecules\":sf_nmolecules,\n",
    "                       \"counterion\": counterion,\n",
    "                       \"ncylinders\":ncylinders,\n",
    "                       \"system_name\":system_name[i*len(preassembly)+j]}\n",
    "            inputs[i*len(preassembly)+j]=my_dict\n",
    "    return inputs\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (jlh-bwCloud)",
   "language": "python",
   "name": "python3-jlh-bwcloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
